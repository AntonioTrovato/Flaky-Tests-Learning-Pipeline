{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416cee15-b5e3-4f58-9aa7-adce40461a4b",
   "metadata": {},
   "source": [
    "# FlakyPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939993d0-6568-410d-adab-a03bda838d62",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "Un flaky test è un'analisi del codice che non riesce a produrre lo stesso risultato ogni volta che viene eseguita la stessa analisi. Ogni volta che viene scritto un nuovo codice per sviluppare o aggiornare software, una pagina Web o un'app, deve essere testato durante tutto il processo di sviluppo per assicurarsi che l'applicazione faccia ciò che dovrebbe fare quando viene rilasciata per l'uso. Logicamente, quando viene sottoposto allo stesso test più e più volte, il codice produrrà lo stesso risultato: l'applicazione funzionerà correttamente ogni volta, superando così il test, o non funzionerà correttamente ogni volta, fallendo così il test.\n",
    "\n",
    "Tuttavia, apparentemente a caso, occasionalmente lo stesso test dello stesso codice produrrà risultati diversi. A volte mostrerà che il codice ha superato il test e l'applicazione ha funzionato come pianificato, e talvolta mostrerà che il codice non ha superato il test e non ha funzionato come previsto. Quando succede questo, il test è considerato flaky.\n",
    "\n",
    "I flaky possono essere causati da vari fattori:\n",
    "1. un problema con il codice appena scritto\n",
    "2. un problema con il test stesso\n",
    "3. alcuni fattori esterni che compromettono i risultati del test\n",
    "\n",
    "Non è sempre facile individuare tali testi, può capitare che eseguiamo un test 10000 volte ed avremo sempre lo stesso risultato, ma se eseguissimo il test un ulteriore volta avremo un risultato diverso. Lo scopo di \"FlakyPipeline\" e di utilizzare il machine learnig per determinare se un test può essere considerato flaky oppure no.\n",
    "\n",
    "## Data Understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7fb3cf28-09af-4dcc-8780-b1595f126b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   id nameProject                                           testCase  \\\n0  36     alluxio               tachyon.userinfotest.constructortest   \n1   2     alluxio             tachyon.masterclienttest.openclosetest   \n2   5     alluxio  tachyon.workerservicehandlertest.overcapacityr...   \n3   6     alluxio  tachyon.workerservicehandlertest.totalovercapa...   \n4   7     alluxio   tachyon.workerservicehandlertest.returnspacetest   \n\n       tloc  tmcCabe  assertionDensity  assertionRoulette  mysteryGuest  \\\n0  0.025907    0.125          0.093176           0.021277      0.000000   \n1  0.062176    0.125          0.473047           0.085106      0.166667   \n2  0.015544    0.125          0.419291           0.042553      0.000000   \n3  0.025907    0.125          0.652231           0.085106      0.000000   \n4  0.036269    0.250          0.489173           0.085106      0.000000   \n\n   eagerTest  sensitiveEquality  ...       mpc  halsteadVocabulary  \\\n0   0.023810                0.0  ...  0.013619            0.007587   \n1   0.142857                0.0  ...  0.377432            0.226801   \n2   0.023810                0.0  ...  0.025292            0.013019   \n3   0.023810                0.0  ...  0.025292            0.013019   \n4   0.047619                0.0  ...  0.025292            0.013019   \n\n   halsteadLength  halsteadVolume  classDataShouldBePrivate  complexClass  \\\n0        0.030129        0.017451                       0.0      0.000000   \n1        0.178862        0.162119                       0.0      0.391081   \n2        0.034912        0.022138                       0.0      0.000000   \n3        0.034912        0.022138                       0.0      0.000000   \n4        0.034912        0.022138                       0.0      0.000000   \n\n   functionalDecomposition  godClass  spaghettiCode  isFlaky  \n0                      0.0  0.046144       0.000000    False  \n1                      0.0  0.046144       0.057664     True  \n2                      0.0  0.046144       0.000000     True  \n3                      0.0  0.046144       0.000000     True  \n4                      0.0  0.046144       0.000000     True  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>nameProject</th>\n      <th>testCase</th>\n      <th>tloc</th>\n      <th>tmcCabe</th>\n      <th>assertionDensity</th>\n      <th>assertionRoulette</th>\n      <th>mysteryGuest</th>\n      <th>eagerTest</th>\n      <th>sensitiveEquality</th>\n      <th>...</th>\n      <th>mpc</th>\n      <th>halsteadVocabulary</th>\n      <th>halsteadLength</th>\n      <th>halsteadVolume</th>\n      <th>classDataShouldBePrivate</th>\n      <th>complexClass</th>\n      <th>functionalDecomposition</th>\n      <th>godClass</th>\n      <th>spaghettiCode</th>\n      <th>isFlaky</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36</td>\n      <td>alluxio</td>\n      <td>tachyon.userinfotest.constructortest</td>\n      <td>0.025907</td>\n      <td>0.125</td>\n      <td>0.093176</td>\n      <td>0.021277</td>\n      <td>0.000000</td>\n      <td>0.023810</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.013619</td>\n      <td>0.007587</td>\n      <td>0.030129</td>\n      <td>0.017451</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.000000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>alluxio</td>\n      <td>tachyon.masterclienttest.openclosetest</td>\n      <td>0.062176</td>\n      <td>0.125</td>\n      <td>0.473047</td>\n      <td>0.085106</td>\n      <td>0.166667</td>\n      <td>0.142857</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.377432</td>\n      <td>0.226801</td>\n      <td>0.178862</td>\n      <td>0.162119</td>\n      <td>0.0</td>\n      <td>0.391081</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.057664</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>alluxio</td>\n      <td>tachyon.workerservicehandlertest.overcapacityr...</td>\n      <td>0.015544</td>\n      <td>0.125</td>\n      <td>0.419291</td>\n      <td>0.042553</td>\n      <td>0.000000</td>\n      <td>0.023810</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.025292</td>\n      <td>0.013019</td>\n      <td>0.034912</td>\n      <td>0.022138</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.000000</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>alluxio</td>\n      <td>tachyon.workerservicehandlertest.totalovercapa...</td>\n      <td>0.025907</td>\n      <td>0.125</td>\n      <td>0.652231</td>\n      <td>0.085106</td>\n      <td>0.000000</td>\n      <td>0.023810</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.025292</td>\n      <td>0.013019</td>\n      <td>0.034912</td>\n      <td>0.022138</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.000000</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>alluxio</td>\n      <td>tachyon.workerservicehandlertest.returnspacetest</td>\n      <td>0.036269</td>\n      <td>0.250</td>\n      <td>0.489173</td>\n      <td>0.085106</td>\n      <td>0.000000</td>\n      <td>0.047619</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.025292</td>\n      <td>0.013019</td>\n      <td>0.034912</td>\n      <td>0.022138</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.000000</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "DATASET_NAME='flakeFlagger.csv'\n",
    "\n",
    "def loadingDataSet(datasetname):\n",
    "    current_directory=os.getcwd()\n",
    "    csv_path = os.path.join(current_directory, datasetname)\n",
    "    return pandas.read_csv(csv_path)\n",
    "\n",
    "\n",
    "dataset=loadingDataSet(DATASET_NAME)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51f70600-404c-4a1e-a1b2-8a734e83152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9785 entries, 0 to 9784\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        9785 non-null   int64  \n",
      " 1   nameProject               9785 non-null   object \n",
      " 2   testCase                  9785 non-null   object \n",
      " 3   tloc                      9785 non-null   float64\n",
      " 4   tmcCabe                   9785 non-null   float64\n",
      " 5   assertionDensity          9785 non-null   float64\n",
      " 6   assertionRoulette         9785 non-null   float64\n",
      " 7   mysteryGuest              9785 non-null   float64\n",
      " 8   eagerTest                 9785 non-null   float64\n",
      " 9   sensitiveEquality         9785 non-null   float64\n",
      " 10  resourceOptimism          9785 non-null   float64\n",
      " 11  conditionalTestLogic      9785 non-null   float64\n",
      " 12  fireAndForget             9785 non-null   float64\n",
      " 13  loc                       9785 non-null   float64\n",
      " 14  lcom2                     9785 non-null   float64\n",
      " 15  lcom5                     9785 non-null   float64\n",
      " 16  cbo                       9785 non-null   float64\n",
      " 17  wmc                       9785 non-null   float64\n",
      " 18  rfc                       9785 non-null   float64\n",
      " 19  mpc                       9785 non-null   float64\n",
      " 20  halsteadVocabulary        9785 non-null   float64\n",
      " 21  halsteadLength            9785 non-null   float64\n",
      " 22  halsteadVolume            9785 non-null   float64\n",
      " 23  classDataShouldBePrivate  9785 non-null   float64\n",
      " 24  complexClass              9785 non-null   float64\n",
      " 25  functionalDecomposition   9785 non-null   float64\n",
      " 26  godClass                  9785 non-null   float64\n",
      " 27  spaghettiCode             9785 non-null   float64\n",
      " 28  isFlaky                   9785 non-null   bool   \n",
      "dtypes: bool(1), float64(25), int64(1), object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df4380-e261-4978-8407-0be74be0d1a6",
   "metadata": {},
   "source": [
    "\n",
    "| Features | Descrizione |\n",
    "| --- | --- | \n",
    "| Id ||\n",
    "| NameProject | |\n",
    "| TestCase | |\n",
    "| tloc | Numero di righe di codice della test suit |\n",
    "| tmcCabe | Somma delle complessità ciclomatiche di tutti i metodi di una classe |\n",
    "| assertionDensity | Percentuali di asserzioni presenti nella test suit |\n",
    "| assertionRoulette | Metrica che indica se il test ha più di una asserzione non documentata |\n",
    "| mysteryGuest | Metrica che indica se il test utilizza una risorsa esterna (es: database,file ...) |\n",
    "| eagerTest | Metricha che indica se un test invoca diversi metodi dell'oggetto di produzione.|\n",
    "| sensitiveEquality | Indica se il metodo toString e utilizzado nel test|\n",
    "| resourceOptimism | Metodo che fa assunzioni ottimistiche sull'esistenza di una risorsa (es file) utilizzata all'interno di esso |\n",
    "| conditionalTestLogic ||\n",
    "| fireAndForget | Test che termina prematuramente in quanto non aspetta le risposte delle chiamate esterne |\n",
    "| loc | line di codice comprendendo anche i commenti | \n",
    "| locm2 |  | \n",
    "| locm5 |  |\n",
    "| cbo | Numero di dipendenze di una classe con altre classi |\n",
    "| wmc | Somma delle complessità ciclomatiche di tutti i metodi di una classe | \n",
    "| rfc | Numero di metodi (compresi quelli ereditari) che possono essere chiamati da altre classi |\n",
    "| mpc |  |\n",
    "| halsteadVocabulary | Gaussian |\n",
    "| halsteadLength | Numero totale di operatori e operandi distinti un una funzione |\n",
    "| halsteadVolume | Memoria (in bit) necessaria per memorizzare il programma |\n",
    "| classDataShouldBePrivate | Classe che espone i suoi attributi, violando il principio dell'information hiding. |\n",
    "| complexClass | Complessita ciclomatica di una classe, ovvero il numero di cammini linearmente indipendeti all'interno della classe|\n",
    "| functionalDecomposition | Metrica che indica se in una classe ereditarietà e polimorfismo sono utilizzate in modo sbagliato. |\n",
    "| godClass | Classe di grandi dimensioni che implementa diverse responsabilità |\n",
    "| spaghettiCode | Classe non possiedie una struttura coerente ad esempio un metodo eccessivamente lungo che non possiede parametri |\n",
    "| isFlaky | Booleano che indica se il test è flaky oppure no |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a77c1da6-268f-41ee-9e5d-4b2e2db4d928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                  id      nameProject  \\\ncount    9785.000000             9785   \nunique           NaN               18   \ntop              NaN  incubator-dubbo   \nfreq             NaN             1681   \nmean     7127.771794              NaN   \nstd      3992.321303              NaN   \nmin         2.000000              NaN   \n25%      4275.000000              NaN   \n50%      7227.000000              NaN   \n75%     10398.000000              NaN   \nmax     14126.000000              NaN   \n\n                                                 testCase         tloc  \\\ncount                                                9785  9785.000000   \nunique                                               9342          NaN   \ntop     controllers.loginlogoutcontrollertest.testlogi...          NaN   \nfreq                                                   16          NaN   \nmean                                                  NaN     0.048908   \nstd                                                   NaN     0.054223   \nmin                                                   NaN     0.005181   \n25%                                                   NaN     0.020725   \n50%                                                   NaN     0.031088   \n75%                                                   NaN     0.056995   \nmax                                                   NaN     1.000000   \n\n            tmcCabe  assertionDensity  assertionRoulette  mysteryGuest  \\\ncount   9785.000000       9785.000000        9785.000000   9785.000000   \nunique          NaN               NaN                NaN           NaN   \ntop             NaN               NaN                NaN           NaN   \nfreq            NaN               NaN                NaN           NaN   \nmean       0.144047          0.073269           0.028109      0.013132   \nstd        0.114475          0.115873           0.054004      0.063745   \nmin        0.000000          0.000000           0.000000      0.000000   \n25%        0.125000          0.000000           0.000000      0.000000   \n50%        0.125000          0.000000           0.021277      0.000000   \n75%        0.250000          0.111811           0.021277      0.000000   \nmax        1.000000          1.000000           0.978723      1.000000   \n\n          eagerTest  sensitiveEquality  ...          mpc  halsteadVocabulary  \\\ncount   9785.000000        9785.000000  ...  9785.000000         9785.000000   \nunique          NaN                NaN  ...          NaN                 NaN   \ntop             NaN                NaN  ...          NaN                 NaN   \nfreq            NaN                NaN  ...          NaN                 NaN   \nmean       0.036944           0.006711  ...     0.072381            0.048549   \nstd        0.058367           0.043813  ...     0.134192            0.081089   \nmin        0.000000           0.000000  ...     0.000000            0.000000   \n25%        0.000000           0.000000  ...     0.000000            0.008754   \n50%        0.023810           0.000000  ...     0.027237            0.021639   \n75%        0.047619           0.000000  ...     0.077821            0.055937   \nmax        1.000000           1.000000  ...     1.000000            0.611762   \n\n        halsteadLength  halsteadVolume  classDataShouldBePrivate  \\\ncount      9785.000000     9785.000000               9785.000000   \nunique             NaN             NaN                       NaN   \ntop                NaN             NaN                       NaN   \nfreq               NaN             NaN                       NaN   \nmean          0.109700        0.087641                  0.008233   \nstd           0.147238        0.140299                  0.053316   \nmin           0.000000        0.000000                  0.000000   \n25%           0.032520        0.019027                  0.000000   \n50%           0.064562        0.042651                  0.000000   \n75%           0.123386        0.090445                  0.000000   \nmax           1.000000        1.000000                  1.000000   \n\n        complexClass  functionalDecomposition     godClass  spaghettiCode  \\\ncount    9785.000000              9785.000000  9785.000000    9785.000000   \nunique           NaN                      NaN          NaN            NaN   \ntop              NaN                      NaN          NaN            NaN   \nfreq             NaN                      NaN          NaN            NaN   \nmean        0.022893                 0.067195     0.046236       0.021554   \nstd         0.138874                 0.235054     0.009654       0.127027   \nmin         0.000000                 0.000000     0.000000       0.000000   \n25%         0.000000                 0.000000     0.046144       0.000000   \n50%         0.000000                 0.000000     0.046144       0.000000   \n75%         0.000000                 0.000000     0.046144       0.000000   \nmax         1.000000                 1.000000     1.000000       0.917693   \n\n        isFlaky  \ncount      9785  \nunique        2  \ntop       False  \nfreq       9115  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  \n\n[11 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>nameProject</th>\n      <th>testCase</th>\n      <th>tloc</th>\n      <th>tmcCabe</th>\n      <th>assertionDensity</th>\n      <th>assertionRoulette</th>\n      <th>mysteryGuest</th>\n      <th>eagerTest</th>\n      <th>sensitiveEquality</th>\n      <th>...</th>\n      <th>mpc</th>\n      <th>halsteadVocabulary</th>\n      <th>halsteadLength</th>\n      <th>halsteadVolume</th>\n      <th>classDataShouldBePrivate</th>\n      <th>complexClass</th>\n      <th>functionalDecomposition</th>\n      <th>godClass</th>\n      <th>spaghettiCode</th>\n      <th>isFlaky</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9785.000000</td>\n      <td>9785</td>\n      <td>9785</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>...</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785.000000</td>\n      <td>9785</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>18</td>\n      <td>9342</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>incubator-dubbo</td>\n      <td>controllers.loginlogoutcontrollertest.testlogi...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>1681</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9115</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7127.771794</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.048908</td>\n      <td>0.144047</td>\n      <td>0.073269</td>\n      <td>0.028109</td>\n      <td>0.013132</td>\n      <td>0.036944</td>\n      <td>0.006711</td>\n      <td>...</td>\n      <td>0.072381</td>\n      <td>0.048549</td>\n      <td>0.109700</td>\n      <td>0.087641</td>\n      <td>0.008233</td>\n      <td>0.022893</td>\n      <td>0.067195</td>\n      <td>0.046236</td>\n      <td>0.021554</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3992.321303</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.054223</td>\n      <td>0.114475</td>\n      <td>0.115873</td>\n      <td>0.054004</td>\n      <td>0.063745</td>\n      <td>0.058367</td>\n      <td>0.043813</td>\n      <td>...</td>\n      <td>0.134192</td>\n      <td>0.081089</td>\n      <td>0.147238</td>\n      <td>0.140299</td>\n      <td>0.053316</td>\n      <td>0.138874</td>\n      <td>0.235054</td>\n      <td>0.009654</td>\n      <td>0.127027</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.005181</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4275.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.020725</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.008754</td>\n      <td>0.032520</td>\n      <td>0.019027</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046144</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7227.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.031088</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.021277</td>\n      <td>0.000000</td>\n      <td>0.023810</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.027237</td>\n      <td>0.021639</td>\n      <td>0.064562</td>\n      <td>0.042651</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046144</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>10398.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.056995</td>\n      <td>0.250000</td>\n      <td>0.111811</td>\n      <td>0.021277</td>\n      <td>0.000000</td>\n      <td>0.047619</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.077821</td>\n      <td>0.055937</td>\n      <td>0.123386</td>\n      <td>0.090445</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046144</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>14126.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.978723</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.611762</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.917693</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c7d4e-a822-47ea-9b5e-c958a5a3af0a",
   "metadata": {},
   "source": [
    "Il dataset da utlizzare non possiede valori nulli, pertando non sara necessario eseguire operazioni di \"Data Cleaning\" tuttavia, risulta essere sbilanciato in quanto sono presenti 9115/9785 campioni di test la cui label isFlaky e False.\n",
    "\n",
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9388d6-a07f-4542-a1c5-5593e31e5854",
   "metadata": {},
   "source": [
    "### Partizionamento DataSet\n",
    "Prima di manipolare il dataset, in modo da ottimizzare l'estrazione di un modello predittivo, esso verra diviso in train-set(80%) e test-set(20%).\n",
    "Il tain-set sarà utlizzato per l'identificazione di un modello predittivo, mentre il test-set verrà utilizzato per testare l'algoritmo di machine learnin.\n",
    "Per il partizionamento del dataset si puo adottare un  partizionamento random oppure un campionamento statificato, ma essendo il dataset abbastanza piccolo e sbilanciato si e deciso di utilizzare il secondo metodo.\n",
    "Il campiomanento viene effettuato sull attributo 'isFlaky', in modo da mantenere le stesse proporzioni per i valori del attributo del dataset di partenza.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21c51ab2-4d0f-4444-99d3-823fde0108af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione Train-set  7828\n",
      "Dimensione Test-set  1957\n",
      "Proporzioni attributo isFlaky dataset di partenza:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": "False    0.931528\nTrue     0.068472\nName: isFlaky, dtype: float64"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index_stratified,test_index_stratified in split.split(dataset,dataset['isFlaky']):\n",
    "    train_set=dataset.loc[train_index_stratified]\n",
    "    test_set=dataset.loc[test_index_stratified]\n",
    "\n",
    "print(\"Dimensione Train-set \",len(train_set))\n",
    "print(\"Dimensione Test-set \",len(test_set))\n",
    "print(\"Proporzioni attributo isFlaky dataset di partenza:\\n \")\n",
    "dataset['isFlaky'].value_counts()/len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7642b1c0-838a-4420-b093-9db1ef9e27a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporzioni attributo isFlaky test-set:\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": "False    0.931528\nTrue     0.068472\nName: isFlaky, dtype: float64"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Proporzioni attributo isFlaky test-set:\\n \")\n",
    "test_set['isFlaky'].value_counts()/len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343bb97-5977-430d-94e7-34b92ffd7fb4",
   "metadata": {},
   "source": [
    "### Preparazione dei dati per l'estrazione di un modello\n",
    "In tale fase andre ad effettuare delle trasformazioni sul test-set in modo da ottimizzare l'estrazione di un modello predittivo.\n",
    "La prima operazione che si dovrebbe effettuare e quella del \"Data Cleaning\". In alcuni casi quando si raccolgono i dati per creare un data set, non si riesce sempre a ricavare tutti gli attributi per un determinato campione, in tal caso esso presentera dei valori null. Tali valori sono un problema per gli algoritmi di machine learning, pertanto devono essere risolti.\n",
    "Nel nostro caso possiamo saltare tale passaggio in quanto da come si evince nella decrizione del dataset non sono presenti valori mancanti.\n",
    "Il passo successivo e quello della \"Feature Construction\". In tale fase si andremo a manipolare le caratteristiche rendendole piu efficienti per un compito di data maining.\n",
    "In tale fase eseguiremo una riduzione della dimensionalita, ovvero cercheremo di ridurre le caratteristiche cercando di mantenere queante piu informazioni possibili.\n",
    "La tecnica che viene applicata e la PCA (Analisi delle componenti principali).\n",
    "\n",
    "Tuttavia la PCA risulta esser più efficiente su dati standardizzati. Per tale motivo verra eseguita prima la standardizzazione.\n",
    "#### Standardizzazione\n",
    "![](Standardizzazione.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e993ccff-452e-4990-a658-c3546e2e0f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Non Standardizzato\n"
     ]
    },
    {
     "data": {
      "text/plain": "          tloc  tmcCabe  assertionDensity  assertionRoulette  mysteryGuest  \\\n3199  0.031088    0.125          0.000000           0.000000           0.0   \n8425  0.046632    0.000          0.000000           0.000000           0.0   \n3509  0.025907    0.125          0.093176           0.042553           0.0   \n4988  0.020725    0.000          0.111811           0.042553           0.0   \n2759  0.036269    0.125          0.069882           0.000000           0.0   \n\n      eagerTest  sensitiveEquality  resourceOptimism  conditionalTestLogic  \\\n3199   0.000000                0.0               0.0               0.02381   \n8425   0.047619                0.0               0.0               0.00000   \n3509   0.071429                0.0               0.0               0.00000   \n4988   0.023810                0.0               0.0               0.00000   \n2759   0.000000                0.0               0.0               0.00000   \n\n      fireAndForget  ...       rfc       mpc  halsteadVocabulary  \\\n3199            0.0  ...  0.004886  0.000000            0.002694   \n8425            0.0  ...  0.065147  0.066148            0.028866   \n3509            0.0  ...  0.022801  0.000000            0.011178   \n4988            0.0  ...  0.071661  0.052529            0.022626   \n2759            0.0  ...  0.003257  0.000000            0.000853   \n\n      halsteadLength  halsteadVolume  classDataShouldBePrivate  complexClass  \\\n3199        0.018651        0.009008                       0.0           0.0   \n8425        0.094213        0.065515                       0.0           0.0   \n3509        0.047346        0.028766                       0.0           0.0   \n4988        0.063606        0.043060                       0.0           0.0   \n2759        0.004782        0.002092                       0.0           0.0   \n\n      functionalDecomposition  godClass  spaghettiCode  \n3199                      0.0  0.046144            0.0  \n8425                      0.0  0.046144            0.0  \n3509                      0.0  0.046144            0.0  \n4988                      0.0  0.046144            0.0  \n2759                      0.0  0.046144            0.0  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tloc</th>\n      <th>tmcCabe</th>\n      <th>assertionDensity</th>\n      <th>assertionRoulette</th>\n      <th>mysteryGuest</th>\n      <th>eagerTest</th>\n      <th>sensitiveEquality</th>\n      <th>resourceOptimism</th>\n      <th>conditionalTestLogic</th>\n      <th>fireAndForget</th>\n      <th>...</th>\n      <th>rfc</th>\n      <th>mpc</th>\n      <th>halsteadVocabulary</th>\n      <th>halsteadLength</th>\n      <th>halsteadVolume</th>\n      <th>classDataShouldBePrivate</th>\n      <th>complexClass</th>\n      <th>functionalDecomposition</th>\n      <th>godClass</th>\n      <th>spaghettiCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3199</th>\n      <td>0.031088</td>\n      <td>0.125</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02381</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.004886</td>\n      <td>0.000000</td>\n      <td>0.002694</td>\n      <td>0.018651</td>\n      <td>0.009008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8425</th>\n      <td>0.046632</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.047619</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.065147</td>\n      <td>0.066148</td>\n      <td>0.028866</td>\n      <td>0.094213</td>\n      <td>0.065515</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3509</th>\n      <td>0.025907</td>\n      <td>0.125</td>\n      <td>0.093176</td>\n      <td>0.042553</td>\n      <td>0.0</td>\n      <td>0.071429</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.022801</td>\n      <td>0.000000</td>\n      <td>0.011178</td>\n      <td>0.047346</td>\n      <td>0.028766</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4988</th>\n      <td>0.020725</td>\n      <td>0.000</td>\n      <td>0.111811</td>\n      <td>0.042553</td>\n      <td>0.0</td>\n      <td>0.023810</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.071661</td>\n      <td>0.052529</td>\n      <td>0.022626</td>\n      <td>0.063606</td>\n      <td>0.043060</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2759</th>\n      <td>0.036269</td>\n      <td>0.125</td>\n      <td>0.069882</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.003257</td>\n      <td>0.000000</td>\n      <td>0.000853</td>\n      <td>0.004782</td>\n      <td>0.002092</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.046144</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "train_dataset=train_set.drop(['id','nameProject','testCase','isFlaky'],axis=1)\n",
    "train_dataset_lable=train_set['isFlaky']\n",
    "\n",
    "#Standardizzo il dataset\n",
    "sc=StandardScaler()\n",
    "X_train_dataset=sc.fit_transform(train_dataset)\n",
    "print('Train-Set Non Standardizzato')\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e15d36de-6571-4cb6-8997-f2ea628cc947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Standardizzato\n"
     ]
    },
    {
     "data": {
      "text/plain": "       tloc   tmcCabe  assertionDensity  assertionRoulette  mysteryGuest  \\\n0 -0.327435 -0.164579         -0.626339          -0.518872     -0.208723   \n1 -0.041729 -1.268545         -0.626339          -0.518872     -0.208723   \n2 -0.422670 -0.164579          0.168013           0.261255     -0.208723   \n3 -0.517905 -1.268545          0.326883           0.261255     -0.208723   \n4 -0.232200 -0.164579         -0.030575          -0.518872     -0.208723   \n\n   eagerTest  sensitiveEquality  resourceOptimism  conditionalTestLogic  \\\n0  -0.624902          -0.157507         -0.116509              0.192097   \n1   0.173097          -0.157507         -0.116509             -0.375993   \n2   0.572096          -0.157507         -0.116509             -0.375993   \n3  -0.225903          -0.157507         -0.116509             -0.375993   \n4  -0.624902          -0.157507         -0.116509             -0.375993   \n\n   fireAndForget  ...       rfc       mpc  halsteadVocabulary  halsteadLength  \\\n0      -0.078422  ... -0.552789 -0.533833           -0.560108       -0.612523   \n1      -0.078422  ... -0.153206 -0.047103           -0.240784       -0.105314   \n2      -0.078422  ... -0.433994 -0.533833           -0.456588       -0.419912   \n3      -0.078422  ... -0.110008 -0.147312           -0.316918       -0.310766   \n4      -0.078422  ... -0.563589 -0.533833           -0.582565       -0.705618   \n\n   halsteadVolume  classDataShouldBePrivate  complexClass  \\\n0       -0.555495                 -0.156408     -0.167662   \n1       -0.157712                 -0.156408     -0.167662   \n2       -0.416407                 -0.156408     -0.167662   \n3       -0.315787                 -0.156408     -0.167662   \n4       -0.604174                 -0.156408     -0.167662   \n\n   functionalDecomposition  godClass  spaghettiCode  \n0                -0.293615 -0.010744      -0.172473  \n1                -0.293615 -0.010744      -0.172473  \n2                -0.293615 -0.010744      -0.172473  \n3                -0.293615 -0.010744      -0.172473  \n4                -0.293615 -0.010744      -0.172473  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tloc</th>\n      <th>tmcCabe</th>\n      <th>assertionDensity</th>\n      <th>assertionRoulette</th>\n      <th>mysteryGuest</th>\n      <th>eagerTest</th>\n      <th>sensitiveEquality</th>\n      <th>resourceOptimism</th>\n      <th>conditionalTestLogic</th>\n      <th>fireAndForget</th>\n      <th>...</th>\n      <th>rfc</th>\n      <th>mpc</th>\n      <th>halsteadVocabulary</th>\n      <th>halsteadLength</th>\n      <th>halsteadVolume</th>\n      <th>classDataShouldBePrivate</th>\n      <th>complexClass</th>\n      <th>functionalDecomposition</th>\n      <th>godClass</th>\n      <th>spaghettiCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.327435</td>\n      <td>-0.164579</td>\n      <td>-0.626339</td>\n      <td>-0.518872</td>\n      <td>-0.208723</td>\n      <td>-0.624902</td>\n      <td>-0.157507</td>\n      <td>-0.116509</td>\n      <td>0.192097</td>\n      <td>-0.078422</td>\n      <td>...</td>\n      <td>-0.552789</td>\n      <td>-0.533833</td>\n      <td>-0.560108</td>\n      <td>-0.612523</td>\n      <td>-0.555495</td>\n      <td>-0.156408</td>\n      <td>-0.167662</td>\n      <td>-0.293615</td>\n      <td>-0.010744</td>\n      <td>-0.172473</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.041729</td>\n      <td>-1.268545</td>\n      <td>-0.626339</td>\n      <td>-0.518872</td>\n      <td>-0.208723</td>\n      <td>0.173097</td>\n      <td>-0.157507</td>\n      <td>-0.116509</td>\n      <td>-0.375993</td>\n      <td>-0.078422</td>\n      <td>...</td>\n      <td>-0.153206</td>\n      <td>-0.047103</td>\n      <td>-0.240784</td>\n      <td>-0.105314</td>\n      <td>-0.157712</td>\n      <td>-0.156408</td>\n      <td>-0.167662</td>\n      <td>-0.293615</td>\n      <td>-0.010744</td>\n      <td>-0.172473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.422670</td>\n      <td>-0.164579</td>\n      <td>0.168013</td>\n      <td>0.261255</td>\n      <td>-0.208723</td>\n      <td>0.572096</td>\n      <td>-0.157507</td>\n      <td>-0.116509</td>\n      <td>-0.375993</td>\n      <td>-0.078422</td>\n      <td>...</td>\n      <td>-0.433994</td>\n      <td>-0.533833</td>\n      <td>-0.456588</td>\n      <td>-0.419912</td>\n      <td>-0.416407</td>\n      <td>-0.156408</td>\n      <td>-0.167662</td>\n      <td>-0.293615</td>\n      <td>-0.010744</td>\n      <td>-0.172473</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.517905</td>\n      <td>-1.268545</td>\n      <td>0.326883</td>\n      <td>0.261255</td>\n      <td>-0.208723</td>\n      <td>-0.225903</td>\n      <td>-0.157507</td>\n      <td>-0.116509</td>\n      <td>-0.375993</td>\n      <td>-0.078422</td>\n      <td>...</td>\n      <td>-0.110008</td>\n      <td>-0.147312</td>\n      <td>-0.316918</td>\n      <td>-0.310766</td>\n      <td>-0.315787</td>\n      <td>-0.156408</td>\n      <td>-0.167662</td>\n      <td>-0.293615</td>\n      <td>-0.010744</td>\n      <td>-0.172473</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.232200</td>\n      <td>-0.164579</td>\n      <td>-0.030575</td>\n      <td>-0.518872</td>\n      <td>-0.208723</td>\n      <td>-0.624902</td>\n      <td>-0.157507</td>\n      <td>-0.116509</td>\n      <td>-0.375993</td>\n      <td>-0.078422</td>\n      <td>...</td>\n      <td>-0.563589</td>\n      <td>-0.533833</td>\n      <td>-0.582565</td>\n      <td>-0.705618</td>\n      <td>-0.604174</td>\n      <td>-0.156408</td>\n      <td>-0.167662</td>\n      <td>-0.293615</td>\n      <td>-0.010744</td>\n      <td>-0.172473</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train-Set Standardizzato')\n",
    "sc_train_dataset=pandas.DataFrame(X_train_dataset,columns=train_dataset.columns)\n",
    "sc_train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7e475-1f7f-43e7-91b6-3d03336fa9c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PCA (Principal Component Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e787348e-e117-477f-9318-e6790491fa37",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [84]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#Decompongo la matrice di covarianza in un vettore composto dagli autovalori e i corrispondenti autovalori conservati come colonne in una matrice 25x25\u001B[39;00m\n\u001B[0;32m      7\u001B[0m eigen_vals, eigen_vecs\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39meig(cov_mat)\n\u001B[1;32m----> 8\u001B[0m tot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43meigen_vals\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m var_exp\u001B[38;5;241m=\u001B[39m[(i\u001B[38;5;241m/\u001B[39mtot) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(eigen_vals,reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)]\n\u001B[0;32m     10\u001B[0m cum_var_exp\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mcumsum(var_exp)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Costruisco la matrice di covarianza\n",
    "cov_mat=np.cov(X_train_dataset.T) #Calcolo la matrice di covarianza del dataset di addestramento standardizzato\n",
    "#Decompongo la matrice di covarianza in un vettore composto dagli autovalori e i corrispondenti autovalori conservati come colonne in una matrice 25x25\n",
    "\n",
    "eigen_vals, eigen_vecs=np.linalg.eig(cov_mat)\n",
    "tot=sum(eigen_vals)\n",
    "var_exp=[(i/tot) for i in sorted(eigen_vals,reverse=True)]\n",
    "cum_var_exp=np.cumsum(var_exp)\n",
    "plt.bar(range(1,26),var_exp,alpha=0.5,align='center',label='Varianza Individuale')\n",
    "plt.step(range(1,26),cum_var_exp,where='mid',label='Varianza Comulativa')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.xlabel('Numero Componenti')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972dfbf-070d-4b3c-8a38-6eb7aa115b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=10)\n",
    "principalCompontent=pca.fit_transform(X_train_dataset)\n",
    "pca_train_dataset=pandas.DataFrame(principalCompontent,columns=['Principal Component 1','Principal Component 2','Principal Component  3',\n",
    "                                                                'Principal Component 4','Principal Component 5','Principal Component 6',\n",
    "                                                                'Principal Component 7','Principal Component 8','Principal Component 9',\n",
    "                                                                'Principal Component 10'])\n",
    "\n",
    "print(\"Varianza:\")\n",
    "pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c41175-c4b5-41ff-be09-c68355ba390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum=0\n",
    "for variance in pca.explained_variance_ratio_:\n",
    "    sum=variance+sum\n",
    "\n",
    "print(\"Varianza totale: \",sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fce1b7-9fc5-4f8e-b073-43148f590f35",
   "metadata": {},
   "source": [
    "#### Data Balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7fe179-ea84-49f9-a252-b2405edb0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "plt.title('Dataset non bilanciato')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.scatter(pca_train_dataset.iloc[:, 0], pca_train_dataset.iloc[:, 1], marker='o', c=train_dataset_lable,\n",
    "           s=25, edgecolor='k', cmap=plt.cm.coolwarm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f2b219-b488-4adb-9925-9d8e4e6de4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE(sampling_strategy='auto', k_neighbors=1,random_state=42)\n",
    "X_train_dataset,Y_train_dataset=sm.fit_resample(pca_train_dataset,train_dataset_lable)\n",
    "\n",
    "plt.title('Dataset bilanciato con SMOTE')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.scatter(X_train_dataset.iloc[:, 0], X_train_dataset.iloc[:, 1], marker='o', c=Y_train_dataset,\n",
    "           s=25, edgecolor='k', cmap=plt.cm.coolwarm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b490d-5058-4bc4-8200-34be0d3cb202",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f9fb9-cc7e-431b-bd4d-4c1a4113da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, test_scores =learning_curve(estimator=Perceptron(),\n",
    "                                                       X=X_train_dataset,\n",
    "                                                       y=Y_train_dataset,\n",
    "                                                       train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                       cv=10,\n",
    "                                                       n_jobs=1)\n",
    "train_mean=np.mean(train_scores,axis=1)\n",
    "train_std=np.std(train_scores,axis=1)\n",
    "test_mean=np.mean(test_scores,axis=1)\n",
    "test_std=np.std(test_scores,axis=1)\n",
    "\n",
    "plt.plot(train_sizes,train_mean,color='blue',marker='o',markersize=5,label='training accuracy')\n",
    "plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=0.15,color='blue')\n",
    "plt.plot(train_sizes,test_mean,color='green',linestyle='--',marker='s',markersize=5,label='validation accuracy')\n",
    "plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samplel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Perceptron Accuracy\")\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462af89-c3a4-475b-8c96-904eb1225bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train_sizes, train_scores, test_scores =learning_curve(estimator=DecisionTreeClassifier(),\n",
    "                                                       X=X_train_dataset,\n",
    "                                                       y=Y_train_dataset,\n",
    "                                                       train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                       cv=10,\n",
    "                                                       n_jobs=1)\n",
    "train_mean=np.mean(train_scores,axis=1)\n",
    "train_std=np.std(train_scores,axis=1)\n",
    "test_mean=np.mean(test_scores,axis=1)\n",
    "test_std=np.std(test_scores,axis=1)\n",
    "\n",
    "plt.plot(train_sizes,train_mean,color='blue',marker='o',markersize=5,label='training accuracy')\n",
    "plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=0.15,color='blue')\n",
    "plt.plot(train_sizes,test_mean,color='green',linestyle='--',marker='s',markersize=5,label='validation accuracy')\n",
    "plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samplel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Decision-Tree Accuracy\")\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7b4d7-f947-4bad-8ffe-3a4c6b61d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train_sizes, train_scores, test_scores =learning_curve(estimator=RandomForestClassifier(n_estimators=15),\n",
    "                                                       X=X_train_dataset,\n",
    "                                                       y=Y_train_dataset,\n",
    "                                                       train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                       cv=10,\n",
    "                                                       n_jobs=1)\n",
    "train_mean=np.mean(train_scores,axis=1)\n",
    "train_std=np.std(train_scores,axis=1)\n",
    "test_mean=np.mean(test_scores,axis=1)\n",
    "test_std=np.std(test_scores,axis=1)\n",
    "\n",
    "plt.plot(train_sizes,train_mean,color='blue',marker='o',markersize=5,label='training accuracy')\n",
    "plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=0.15,color='blue')\n",
    "plt.plot(train_sizes,test_mean,color='green',linestyle='--',marker='s',markersize=5,label='validation accuracy')\n",
    "plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samplel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Random Forest Accuracy\")\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7071cb-3170-4fac-9127-1123c546e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "train_sizes, train_scores, test_scores =learning_curve(estimator=SVC(kernel='rbf',C=1.0,random_state=0, gamma=2),\n",
    "                                                       X=X_train_dataset,\n",
    "                                                       y=Y_train_dataset,\n",
    "                                                       cv=10,\n",
    "                                                       n_jobs=1)\n",
    "train_mean=np.mean(train_scores,axis=1)\n",
    "train_std=np.std(train_scores,axis=1)\n",
    "test_mean=np.mean(test_scores,axis=1)\n",
    "test_std=np.std(test_scores,axis=1)\n",
    "\n",
    "plt.plot(train_sizes,train_mean,color='blue',marker='o',markersize=5,label='training accuracy')\n",
    "plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=0.15,color='blue')\n",
    "plt.plot(train_sizes,test_mean,color='green',linestyle='--',marker='s',markersize=5,label='validation accuracy')\n",
    "plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samplel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"SVM Accuracy\")\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-layer Perceptron Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "train_sizes, train_scores, test_scores =learning_curve(estimator=MLPClassifier(solver='lbfgs',alpha=1e-5,\n",
    "                                                                               hidden_layer_sizes=(5,2),random_state=1,max_iter=5000),\n",
    "                                                       X=X_train_dataset,\n",
    "                                                       y=Y_train_dataset,\n",
    "                                                       cv=10,\n",
    "                                                       n_jobs=1)\n",
    "train_mean=np.mean(train_scores,axis=1)\n",
    "train_std=np.std(train_scores,axis=1)\n",
    "test_mean=np.mean(test_scores,axis=1)\n",
    "test_std=np.std(test_scores,axis=1)\n",
    "\n",
    "plt.plot(train_sizes,train_mean,color='blue',marker='o',markersize=5,label='training accuracy')\n",
    "plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=0.15,color='blue')\n",
    "plt.plot(train_sizes,test_mean,color='green',linestyle='--',marker='s',markersize=5,label='validation accuracy')\n",
    "plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samplel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"SVM Accuracy\")\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3d0e0a96-5ab1-4ab3-9ae6-cdbb8fcc2f50",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f9079-3f6a-4978-9f8f-81d3adaea5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ab2d2-8007-451b-a3c5-99e54356e125",
   "metadata": {},
   "source": [
    "| Parameter | Descriprtion |\n",
    "| --- | --- | \n",
    "| Bootrstap | Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.|\n",
    "| ccp_alpha | Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than will be chosen.|\n",
    "| class_weight |Weights associated with classes in the form . If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y|\n",
    "| criterion |The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain|\n",
    "| max_depth |The maximum depth of the tree|\n",
    "| max_features |The number of features to consider when looking for the best split|\n",
    "| max_leaf_nodes |Grow trees with in best-first fashion. Best nodes are defined as relative reduction in impurity.|\n",
    "| max_samples ||\n",
    "| min_impurity_decrease |A node will be split if this split induces a decrease of the impurity greater than or equal to this value|\n",
    "| min_samples_leaf |The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least training samples in each of the left and right branches|\n",
    "| min_samples_split |The minimum number of samples required to split an internal node|\n",
    "| min_weight_fraction_leaf |The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node.|\n",
    "| n_estimators |The number of trees in the forest|\n",
    "| n_jobs |The number of jobs to run in parallel|\n",
    "| oob_score |Whether to use out-of-bag samples to estimate the generalization score|\n",
    "| random_state |Controls both the randomness of the bootstrapping of the samples used when building trees (if ) and the sampling of the features to consider when looking for the best split at each node (if ).|\n",
    "| verbose |Controls the verbosity when fitting and predicting|\n",
    "| warm_start |When set to , reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca5440-32e9-409c-8b41-eb2ffc1cfd66",
   "metadata": {},
   "source": [
    "### Evalutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04112e2b-6561-4aac-afcc-da62e52eebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_set_copy=test_set.copy()\n",
    "test_dataset=test_set.drop(['id','nameProject','testCase','isFlaky'],axis=1)\n",
    "test_dataset_lable=test_set['isFlaky']\n",
    "test_dataset_lable=test_dataset_lable.astype(int)\n",
    "X_test_dataset=sc.transform(test_dataset)\n",
    "principalCompontent=pca.transform(X_test_dataset)\n",
    "pca_test_dataset=pandas.DataFrame(principalCompontent,columns=['Principal Component 1','Principal Component 2','Principal Component  3',\n",
    "                                                                'Principal Component 4','Principal Component 5','Principal Component 6',\n",
    "                                                                'Principal Component 7','Principal Component 8','Principal Component 9',\n",
    "\n",
    "                                                                'Principal Component 10'])\n",
    "randomForest=RandomForestClassifier(n_estimators=40)\n",
    "randomForest.fit(X_train_dataset,Y_train_dataset)\n",
    "test_predict=randomForest.predict(pca_test_dataset)\n",
    "confmat=confusion_matrix(y_true=test_dataset_lable,y_pred=test_predict)\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j,y=i, s=confmat[i,j], va='center', ha='center')\n",
    "plt.xlabel('predict label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "print(\"Accuracy: %.3f\" %accuracy_score(y_true=test_dataset_lable,y_pred=test_predict))\n",
    "print(\"Precision: %.3f\" %precision_score(y_true=test_dataset_lable,y_pred=test_predict))\n",
    "print(\"Recall: %.3f\" %recall_score(y_true=test_dataset_lable,y_pred=test_predict))\n",
    "print(\"F1: %.3f\" %f1_score(y_true=test_dataset_lable,y_pred=test_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_set_copy=test_set.copy()\n",
    "test_dataset=test_set.drop(['id','nameProject','testCase','isFlaky'],axis=1)\n",
    "test_dataset_lable=test_set['isFlaky']\n",
    "test_dataset_lable=test_dataset_lable.astype(int)\n",
    "X_test_dataset=sc.transform(test_dataset)\n",
    "principalCompontent=pca.transform(X_test_dataset)\n",
    "pca_test_dataset=pandas.DataFrame(principalCompontent,columns=['Principal Component 1','Principal Component 2','Principal Component  3',\n",
    "                                                                'Principal Component 4','Principal Component 5','Principal Component 6',\n",
    "                                                                'Principal Component 7','Principal Component 8','Principal Component 9',\n",
    "\n",
    "                                                                'Principal Component 10'])\n",
    "mlpClassifier=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5,2),random_state=1,max_iter=5000)\n",
    "mlpClassifier.fit(X_train_dataset,Y_train_dataset)\n",
    "test_predict=mlpClassifier.predict(pca_test_dataset)\n",
    "confmat=confusion_matrix(y_true=test_dataset_lable,y_pred=test_predict)\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j,y=i, s=confmat[i,j], va='center', ha='center')\n",
    "plt.xlabel('predict label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7871ba-578a-488f-9715-3d3397f9feb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "print(\"Accuracy: %.3f\" %accuracy_score(y_true=test_dataset_lable,y_pred=test_predict))\n",
    "print(\"Precision: %.3f\" %precision_score(y_true=test_dataset_lable,y_pred=test_predict))\n",
    "print(\"Recall: %.3f\" %recall_score(y_true=test_dataset_lable,y_pred=test_predict))\n",
    "print(\"F1: %.3f\" %f1_score(y_true=test_dataset_lable,y_pred=test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ciò significa che fra tutte le predizioni:\n",
    "Accuracy: nel 94% dei casi abbiamo scelto predetto correttamente\n",
    "Precision: tra tutti i casi predetti come True, il 57% di essi erano effettivamente Flaky Test\n",
    "Recall: tutti i casi predetti CORRETTAMENTE come True, sono il 57% dei casi True totali\n",
    "F1: media di Precision e Recall\n",
    "\n",
    "Obiettivo: aumentare la recall, in quanto, a costo di ottenere falsi positivi, è importante rilevare i reali True.\n",
    "Soluzioni: provare Deep Learning e/o effettuare modifiche al dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}